{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('codes.csv',header =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.columns =  ['desc','codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file['codes'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = []\n",
    "sentences = list(file['desc'])\n",
    "for sen in sentences:\n",
    "    descs.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "file['encodes'] = labelencoder.fit_transform(file['codes'])\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"don't be so judgmental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = file['encodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_descs(text_descs):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_descs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_descs = [tokenize_descs(desc) for desc in descs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_with_len = [[desc, y[i], len(desc)]\n",
    "                 for i, desc in enumerate(tokenized_descs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(descs_with_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_with_len.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_descs_labels = [(desc_lab[0], desc_lab[1]) for desc_lab in descs_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_descs_labels, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), (),(),(),()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BATCHES = math.ceil(len(sorted_descs_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 966\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-56d381b00d5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mernie\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m tuples = [(\"This is a positive example. I'm very happy today.\", 1),\n\u001b[0;32m      5\u001b[0m           (\"This is a negative sentence. Everything was wrong today at work.\", 0)]\n",
      "\u001b[1;32mc:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages\\ernie\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mernie\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages\\ernie\\ernie.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m from transformers import (\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mAutoModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModel'"
     ]
    }
   ],
   "source": [
    "from ernie import SentenceClassifier, Models\n",
    "import pandas as pd\n",
    "\n",
    "tuples = [(\"This is a positive example. I'm very happy today.\", 1),\n",
    "          (\"This is a negative sentence. Everything was wrong today at work.\", 0)]\n",
    "\n",
    "df = pd.DataFrame(tuples)\n",
    "classifier = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=128, labels_no=2)\n",
    "classifier.load_dataset(df, validation_split=0.2)\n",
    "classifier.fine_tune(epochs=4, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ernie==0.0.27b0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (0.0.27b0)\n",
      "Requirement already satisfied: pandas>=0.25.3 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from ernie==0.0.27b0) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from ernie==0.0.27b0) (0.23.2)\n",
      "Requirement already satisfied: transformers==2.4.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from ernie==0.0.27b0) (2.4.1)\n",
      "Requirement already satisfied: py-cpuinfo==5.0.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from ernie==0.0.27b0) (5.0.0)\n",
      "Requirement already satisfied: tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from ernie==0.0.27b0) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from pandas>=0.25.3->ernie==0.0.27b0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from pandas>=0.25.3->ernie==0.0.27b0) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from pandas>=0.25.3->ernie==0.0.27b0) (2.8.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from scikit-learn>=0.22.1->ernie==0.0.27b0) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from scikit-learn>=0.22.1->ernie==0.0.27b0) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from scikit-learn>=0.22.1->ernie==0.0.27b0) (2.1.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (1.14.38)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (0.1.91)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (2020.7.14)\n",
      "Requirement already satisfied: requests in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (2.24.0)\n",
      "Requirement already satisfied: tokenizers==0.0.11 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (0.0.11)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (0.0.43)\n",
      "Requirement already satisfied: filelock in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from transformers==2.4.1->ernie==0.0.27b0) (4.48.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.27.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.0.8)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.34.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.8.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (3.12.3)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (2.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.1.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from boto3->transformers==2.4.1->ernie==0.0.27b0) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from boto3->transformers==2.4.1->ernie==0.0.27b0) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.38 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from boto3->transformers==2.4.1->ernie==0.0.27b0) (1.17.38)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from requests->transformers==2.4.1->ernie==0.0.27b0) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from requests->transformers==2.4.1->ernie==0.0.27b0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from requests->transformers==2.4.1->ernie==0.0.27b0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from requests->transformers==2.4.1->ernie==0.0.27b0) (2020.6.20)\n",
      "Requirement already satisfied: click in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from sacremoses->transformers==2.4.1->ernie==0.0.27b0) (7.1.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (2.7.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from protobuf>=3.8.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (49.2.1.post20200807)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.16.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.17.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from botocore<1.18.0,>=1.17.38->boto3->transformers==2.4.1->ernie==0.0.27b0) (0.15.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (4.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\msais\\anaconda3\\envs\\tensorflow22bert\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie==0.0.27b0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install ernie==0.0.27b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = file[\"encodes\"]==141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.loc[file['encodes'] == 141] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
